{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dots & Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about making use of a Q-learning reinforcement algorithm to implement a game-playing agent which learns how to play a game of [3x3](https://www.wikihow.com/images/thumb/c/cb/Win-at-the-Dot-Game-Step-3.jpg/aid608874-v4-900px-Win-at-the-Dot-Game-Step-3.jpg) [Dots and Boxes](https://en.wikipedia.org/wiki/Dots_and_Boxes) optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3x3 Dots & Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dots & boxes is a 2-player game.\n",
    "\n",
    "The starting state is an empty grid of dots (16 dots in case of a 3x3 size board). Both players take turns making a move; a move consists of adding either a horizontal or vertical line between two unjoined adjacent dots. If making a move completes a 1x1 box, then the player who made that move wins that particular box (essentially, gets a point); the player also retains their turn. The game ends when there are no more available moves left to make. The player with the most points number of points is the winner of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining how to store and represent the game is a bit tricky, since both the dots and their intermediate edges are valid to the game state. However, representing both dots and edges is not feasible since doing so requires either multiple lists or nested ones, both of which are not unviable to use as input parameters to the neural network.\n",
    "\n",
    "One can, however, observe that the dots are constant for every state. Hence, a game state can be represented solely by its edges. All edges in the game are represented as a list (of length 24, since there are 24 edges in a 3x3 size game), with 0 denoting that an edge does not exist, and one denoting otherwise.\n",
    "\n",
    "The edge ordering being considered is:\n",
    "\n",
    "**&#183;**&nbsp;&nbsp;&nbsp; 0 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 1 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 2 &nbsp;&nbsp;&nbsp;**&#183;**  \n",
    "12 &nbsp;&nbsp;&nbsp;&nbsp; 13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 14 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 15  \n",
    "**&#183;**&nbsp;&nbsp;&nbsp; 3 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 4 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 5 &nbsp;&nbsp;&nbsp;**&#183;**  \n",
    "16 &nbsp;&nbsp;&nbsp;&nbsp; 17 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 18 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 19  \n",
    "**&#183;**&nbsp;&nbsp;&nbsp; 6 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 7 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp;&nbsp; 8 &nbsp;&nbsp;&nbsp;**&#183;**  \n",
    "20 &nbsp;&nbsp;&nbsp;&nbsp; 21 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 22 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 23  \n",
    "**&#183;**&nbsp;&nbsp;&nbsp; 9 &nbsp;&nbsp;&nbsp;**&#183;**&nbsp;&nbsp; 10 &nbsp;&nbsp;**&#183;**&nbsp;&nbsp; 11 &nbsp;&nbsp;**&#183;**  \n",
    "\n",
    "The index of a value in this list represents the corresponding edge, e.g. if edge 0 exists in a state, then index 0 in the list has value 1, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A module containing simulation functions to train an AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. * `train_simulation(environment, train_agent, target_agent, n_games, update_step, test_agents=None, test_games=None)`: \n",
    "Runs a simulation to train an agent. If test agents are provided, tests the agent at an interval of 1000 iterations and logs the results.\n",
    "\n",
    "        * `environment`: game environment\n",
    "        * `train_agent`: learning agent\n",
    "        * `target_agent`: opponent agent\n",
    "        * `n_games`: number of training games to run\n",
    "        * `update_step`: number of games played until opponent model is updated\n",
    "        * `test_agents`: array of test agents\n",
    "        * `test_games`: number of games to play against test agents\n",
    "        * `return`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. * `output_comparison(training_games=10000, test_games=1000)`:\n",
    "Runs a comparison against 2 agents that are identical aside from the output activation function.\n",
    "    * `training_games`: Number of games to play\n",
    "    * `test_games`: Number of test games to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Directory is: .\\models\\size3\\\n",
      "Log file is: .\\models\\size3\\logs.txt\n",
      "WARNING:tensorflow:From C:\\Users\\gunja\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\gunja\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Attempted load and failed\n",
      "Starting at game 1\n",
      "Game 200 Test Results\n",
      "Current win percentage over agent random_player: 60.80%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 39.20%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.10%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.90%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-200\n",
      "\n",
      "Game 400 Test Results\n",
      "Current win percentage over agent random_player: 60.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 39.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.30%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.70%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.00%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.00%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-400\n",
      "\n",
      "Game 600 Test Results\n",
      "Current win percentage over agent random_player: 60.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 39.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.60%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.40%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-600\n",
      "\n",
      "Replay Table Ready\n",
      "Game 800 Test Results\n",
      "Current win percentage over agent random_player: 62.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 37.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-800\n",
      "\n",
      "Game 1000 Test Results\n",
      "Current win percentage over agent random_player: 44.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 55.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 100.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.10%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.90%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-1000\n",
      "\n",
      "Game 1200 Test Results\n",
      "Current win percentage over agent random_player: 50.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 49.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 100.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.00%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 100.00%\n",
      "\n",
      "Saving current model\n",
      "WARNING:tensorflow:From C:\\Users\\gunja\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-1200\n",
      "\n",
      "Game 1400 Test Results\n",
      "Current win percentage over agent random_player: 58.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 41.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.30%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.70%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.10%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.90%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-1400\n",
      "\n",
      "Game 1600 Test Results\n",
      "Current win percentage over agent random_player: 68.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 31.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.70%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.30%\n",
      "\n",
      "Current win percentage over agent advanced_player: 3.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 96.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-1600\n",
      "\n",
      "Game 1800 Test Results\n",
      "Current win percentage over agent random_player: 64.50%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 35.50%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-1800\n",
      "\n",
      "Game 2000 Test Results\n",
      "Current win percentage over agent random_player: 69.80%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 30.20%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.40%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.60%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-2000\n",
      "\n",
      "Game 2200 Test Results\n",
      "Current win percentage over agent random_player: 69.30%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 30.70%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game 2400 Test Results\n",
      "Current win percentage over agent random_player: 76.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 23.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.10%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.90%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-2400\n",
      "\n",
      "Game 2600 Test Results\n",
      "Current win percentage over agent random_player: 72.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 27.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.40%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.60%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-2600\n",
      "\n",
      "Game 2800 Test Results\n",
      "Current win percentage over agent random_player: 78.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 21.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.50%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.50%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.00%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.00%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-2800\n",
      "\n",
      "Game 3000 Test Results\n",
      "Current win percentage over agent random_player: 72.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 27.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.90%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.10%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-3000\n",
      "\n",
      "Game 3200 Test Results\n",
      "Current win percentage over agent random_player: 70.00%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 30.00%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.10%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.90%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.30%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.70%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-3200\n",
      "\n",
      "Game 3400 Test Results\n",
      "Current win percentage over agent random_player: 65.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 34.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.60%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.40%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.80%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.20%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-3400\n",
      "\n",
      "Game 3600 Test Results\n",
      "Current win percentage over agent random_player: 66.80%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 33.20%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.50%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.50%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.90%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.10%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-3600\n",
      "\n",
      "Game 3800 Test Results\n",
      "Current win percentage over agent random_player: 67.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 32.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 0.80%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.20%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.40%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.60%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-3800\n",
      "\n",
      "Game 4000 Test Results\n",
      "Current win percentage over agent random_player: 65.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 34.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 2.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 97.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-4000\n",
      "\n",
      "Game 4200 Test Results\n",
      "Current win percentage over agent random_player: 70.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 29.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 2.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 97.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-4200\n",
      "\n",
      "Game 4400 Test Results\n",
      "Current win percentage over agent random_player: 81.00%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 19.00%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.50%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.50%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.80%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.20%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-4400\n",
      "\n",
      "Game 4600 Test Results\n",
      "Current win percentage over agent random_player: 78.00%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 22.00%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.90%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.10%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.90%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.10%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-4600\n",
      "\n",
      "Game 4800 Test Results\n",
      "Current win percentage over agent random_player: 80.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 19.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.80%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current win percentage over agent advanced_player: 1.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-4800\n",
      "\n",
      "Game 5000 Test Results\n",
      "Current win percentage over agent random_player: 81.30%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 18.70%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 99.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-5000\n",
      "\n",
      "Game 5200 Test Results\n",
      "Current win percentage over agent random_player: 87.00%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.00%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.10%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.90%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-5200\n",
      "\n",
      "Game 5400 Test Results\n",
      "Current win percentage over agent random_player: 85.50%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 14.50%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.00%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.00%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-5400\n",
      "\n",
      "Game 5600 Test Results\n",
      "Current win percentage over agent random_player: 85.90%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 14.10%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.30%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.70%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-5600\n",
      "\n",
      "Game 5800 Test Results\n",
      "Current win percentage over agent random_player: 86.20%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.80%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.90%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.10%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-5800\n",
      "\n",
      "Game 6000 Test Results\n",
      "Current win percentage over agent random_player: 86.20%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.80%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.90%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.10%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-6000\n",
      "\n",
      "Game 6200 Test Results\n",
      "Current win percentage over agent random_player: 86.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.30%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.70%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-6200\n",
      "\n",
      "Game 6400 Test Results\n",
      "Current win percentage over agent random_player: 87.90%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 12.10%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.10%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.90%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.40%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.60%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-6400\n",
      "\n",
      "Game 6600 Test Results\n",
      "Current win percentage over agent random_player: 87.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 12.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.50%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.50%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-6600\n",
      "\n",
      "Game 6800 Test Results\n",
      "Current win percentage over agent random_player: 87.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 12.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.10%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.90%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-6800\n",
      "\n",
      "Game 7000 Test Results\n",
      "Current win percentage over agent random_player: 86.20%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.80%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.60%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.40%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.00%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 100.00%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-7000\n",
      "\n",
      "Game 7200 Test Results\n",
      "Current win percentage over agent random_player: 90.90%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 9.10%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.70%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.30%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-7200\n",
      "\n",
      "Game 7400 Test Results\n",
      "Current win percentage over agent random_player: 91.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 8.90%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current win percentage over agent moderate_player: 3.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 96.80%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.40%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.60%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-7400\n",
      "\n",
      "Game 7600 Test Results\n",
      "Current win percentage over agent random_player: 92.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 7.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 3.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 96.80%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.80%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.20%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-7600\n",
      "\n",
      "Game 7800 Test Results\n",
      "Current win percentage over agent random_player: 91.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 8.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 1.80%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 98.20%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-7800\n",
      "\n",
      "Game 8000 Test Results\n",
      "Current win percentage over agent random_player: 91.90%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 8.10%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.70%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.30%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-8000\n",
      "\n",
      "Game 8200 Test Results\n",
      "Current win percentage over agent random_player: 88.20%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 11.80%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.80%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.20%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-8200\n",
      "\n",
      "Game 8400 Test Results\n",
      "Current win percentage over agent random_player: 89.80%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 10.20%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.80%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.20%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-8400\n",
      "\n",
      "Game 8600 Test Results\n",
      "Current win percentage over agent random_player: 85.30%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 14.70%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.30%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.70%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.50%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.50%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-8600\n",
      "\n",
      "Game 8800 Test Results\n",
      "Current win percentage over agent random_player: 86.60%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 13.40%\n",
      "\n",
      "Current win percentage over agent moderate_player: 3.50%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 96.50%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.80%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.20%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-8800\n",
      "\n",
      "Game 9000 Test Results\n",
      "Current win percentage over agent random_player: 87.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 12.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 2.40%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 97.60%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-9000\n",
      "\n",
      "Game 9200 Test Results\n",
      "Current win percentage over agent random_player: 88.40%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 11.60%\n",
      "\n",
      "Current win percentage over agent moderate_player: 4.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 95.80%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-9200\n",
      "\n",
      "Game 9400 Test Results\n",
      "Current win percentage over agent random_player: 90.70%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 9.30%\n",
      "\n",
      "Current win percentage over agent moderate_player: 4.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 95.80%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.20%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.80%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-9400\n",
      "\n",
      "Game 9600 Test Results\n",
      "Current win percentage over agent random_player: 89.80%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 10.20%\n",
      "\n",
      "Current win percentage over agent moderate_player: 4.20%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 95.80%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.70%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.30%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-9600\n",
      "\n",
      "Game 9800 Test Results\n",
      "Current win percentage over agent random_player: 91.10%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 8.90%\n",
      "\n",
      "Current win percentage over agent moderate_player: 3.90%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 96.10%\n",
      "\n",
      "Current win percentage over agent advanced_player: 1.60%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 98.40%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game 10000 Test Results\n",
      "Current win percentage over agent random_player: 94.50%\n",
      "Current draw percentage over agent random_player: 0.00%\n",
      "Current loss percentage over agent random_player: 5.50%\n",
      "\n",
      "Current win percentage over agent moderate_player: 3.70%\n",
      "Current draw percentage over agent moderate_player: 0.00%\n",
      "Current loss percentage over agent moderate_player: 96.30%\n",
      "\n",
      "Current win percentage over agent advanced_player: 0.90%\n",
      "Current draw percentage over agent advanced_player: 0.00%\n",
      "Current loss percentage over agent advanced_player: 99.10%\n",
      "\n",
      "Saving current model\n",
      "Loading model into target\n",
      "INFO:tensorflow:Restoring parameters from .\\models\\size3\\-10000\n",
      "\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ai_agents import DQNLearner\n",
    "from naive_players import SimplePlayer\n",
    "from simulation_utils import *\n",
    "import os\n",
    "\n",
    "\n",
    "def train_simulation(environment, train_agent, target_agent, n_games, update_step, test_agents=None, test_games=None):\n",
    "    \n",
    "    # Create a test environment\n",
    "    if test_agents is not None:\n",
    "        test_env = clone(environment)\n",
    "\n",
    "    # Set the players to the environment\n",
    "    environment.player1 = train_agent\n",
    "    environment.player2 = target_agent\n",
    "\n",
    "    # Get the directory to save/load models and log information\n",
    "    model_dir = model_path(environment.size)\n",
    "    log_file = log_path(environment.size)\n",
    "\n",
    "    # For Debugging\n",
    "    print (\"Model Directory is: {}\".format(model_dir))\n",
    "    print (\"Log file is: {}\".format(log_file))\n",
    "\n",
    "    # Start log file if it doesn't exist, otherwise load from last game\n",
    "    if not os.path.exists(log_file) or os.stat(log_file) == 0:\n",
    "        with open(log_file,'a') as file:\n",
    "            game_start = 1\n",
    "            file.write('Game Number,Test Agent,Win Percentage,Draw Percentage,Loss Percentage\\n')\n",
    "    else:\n",
    "        last_line = recent_game(log_file)\n",
    "        if last_line != \"Game Number\":\n",
    "            game_start = int(recent_game(log_file)) + 1\n",
    "        else:\n",
    "            game_start = 1\n",
    "\n",
    "    train_agent.initialize_network()\n",
    "    target_agent.initialize_network()\n",
    "\n",
    "    # Load previous model if it exists\n",
    "    try:\n",
    "        train_agent.load_model(model_dir + '-' + str(game_start - 1))\n",
    "        target_agent.load_model(model_dir + '-' + str(game_start - 1))\n",
    "        print(\"Load Succeeded\")\n",
    "    except:\n",
    "        print(\"Attempted load and failed\")\n",
    "\n",
    "    # Debugging\n",
    "    print (\"Starting at game {}\".format(game_start))\n",
    "\n",
    "    # Begin training games\n",
    "    for game_number in range(game_start, n_games + 1):\n",
    "\n",
    "        # Switch who goes first every other round\n",
    "        environment.player1 = train_agent\n",
    "        environment.player2 = target_agent\n",
    "        if game_number % 2 == 0:\n",
    "            switch_players(environment)\n",
    "\n",
    "        environment.play()\n",
    "\n",
    "        # Write to logs every 1 games\n",
    "        if game_number % 200 == 0 and test_agents:\n",
    "            print(\"Game {} Test Results\".format(game_number))\n",
    "            with open(log_file, 'a') as file:\n",
    "                for agent in test_agents:\n",
    "                    win_percentage, draw_percentage, loss_percentage = test(test_env, train_agent, agent, test_games)\n",
    "                    file.write('{},{},{},{},{}\\n'.format(game_number, agent, win_percentage, draw_percentage, loss_percentage))\n",
    "                    print()\n",
    "\n",
    "        \n",
    "        # Play games agains the old model\n",
    "        if game_number % update_step == 0:\n",
    "\n",
    "            # Give the target agent the most recent model\n",
    "            print(\"Saving current model\")\n",
    "            path = train_agent.save_model(model_dir, global_step=game_number)\n",
    "\n",
    "            # Load model into target\n",
    "            print (\"Loading model into target\")\n",
    "            target_agent.load_model(path)\n",
    "            print ()\n",
    "\n",
    "    print (\"Finished!\")\n",
    "\n",
    "\n",
    "def output_comparison(training_games=10000, test_games=1000):\n",
    "\n",
    "    training_env = DotsAndBoxes(3)\n",
    "    training_env2 = clone(training_env)\n",
    "    test_env = clone(training_env)\n",
    "\n",
    "    tanh_player = DQNLearner('tanh output', alpha=1e-6, gamma=0.6)\n",
    "    linout_player = DQNLearner('linear output', alpha=1e-6, gamma=0.6)\n",
    "    training_opponent = Player('training opponent')\n",
    "    training_opponent2 = Player('training opponent 2')\n",
    "\n",
    "    training_env.player1 = tanh_player\n",
    "    training_env.player2 = training_opponent\n",
    "    tanh_player.initialize_network(output='tanh')\n",
    "\n",
    "    training_env2.player1 = linout_player\n",
    "    training_env2.player2 = training_opponent2\n",
    "    linout_player.initialize_network(output='linear')\n",
    "\n",
    "    test_random = Player('Random')\n",
    "    test_moderate = SimplePlayer('Moderate', level=1)\n",
    "    test_advanced = SimplePlayer('Advanced', level=2)\n",
    "\n",
    "    log_file = '.{0:s}Analysis{0:s}output_comparison.txt'.format(os.sep)\n",
    "    with open(log_file, 'w') as file:\n",
    "        file.write('Learning Agent,Test Agent,Win %, Draw %, Loss %\\n')\n",
    "\n",
    "    for game_number in range(1, training_games+1):\n",
    "\n",
    "        # Switch who goes first every other round\n",
    "        training_env.player1 = tanh_player\n",
    "        training_env.player2 = training_opponent\n",
    "\n",
    "        training_env2.player1 = linout_player\n",
    "        training_env2.player2 = training_opponent2\n",
    "\n",
    "        # Switch starting positions\n",
    "        if game_number % 2 == 0:\n",
    "            switch_players(training_env)\n",
    "            switch_players(training_env2)\n",
    "\n",
    "        training_env.play()\n",
    "        training_env2.play()\n",
    "\n",
    "        if game_number % (training_games/20) == 0:\n",
    "            print(\"Running Tests at game {}\".format(game_number))\n",
    "            for test_agent in (test_random, test_moderate, test_advanced):\n",
    "                for player in (tanh_player, linout_player):\n",
    "                    print(\"Testing player: {}\".format(player))\n",
    "                    wins, draws, loss = test(test_env, player, test_agent, test_games)\n",
    "                    with open(log_file, 'a') as file:\n",
    "                        file.write('{},{},{},{},{}\\n'.format(player, test_agent, wins, draws, loss))\n",
    "                    print()\n",
    "\n",
    "    print (\"Training Completed!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    game_size = 3\n",
    "    train_agent = DQNLearner('train',alpha=1e-6,gamma=0.6)\n",
    "\n",
    "    target_agent = DQNLearner('target')\n",
    "    target_agent.learning = False\n",
    "\n",
    "    # Load the testing agents\n",
    "    test_agent1 = Player(name='random_player')\n",
    "    test_agent2 = SimplePlayer(name='moderate_player', level=1)\n",
    "    test_agent3 = SimplePlayer(name='advanced_player', level=2)\n",
    "    \n",
    "    env = DotsAndBoxes(game_size)\n",
    "    n_games = 10000\n",
    "    update_step = 200\n",
    "    test_games = 1000\n",
    "    \n",
    "    train_simulation(env, train_agent, target_agent,\n",
    "                                    n_games, update_step,\n",
    "                                    [test_agent1,test_agent2,test_agent3], test_games)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
